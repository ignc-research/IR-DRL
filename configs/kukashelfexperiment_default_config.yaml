# config that builds the env for the kuka shelf experiment
run:
  load_model: False  
  model_path: ""  
  train:
    num_envs : 16  
    timesteps: 15000000 
    save_freq : 30000
    save_folder: "./models/weights"  
    save_name: "PPO_default"
    recurrent: False
    ppo_steps: 1024  
    batch_size: 512
    gamma: 0.99  
    tensorboard_folder: "./models/tensorboard_logs"
    custom_policy:
      use: False
      activation_function: "ReLU"  
      layers:
        - 128
        - 128
        - value_function:
          - 64
        - policy_function:
          - 32
          - 32
          - 16   
      lstm:
        lstm_hidden_size: 512
        n_lstm_layers: 2
        shared_lstm: False
        enable_critic_lstm: True

  eval:
    max_episodes: -1  
    logging: 1  
    display_delay: 0.00416666666 
    show_world_aux: True
    show_goal_aux: True
    show_sensor_aux: False
    pybullet_recorder:
      use: False
      save_path: "demo"
      scale: 1

env:
  max_steps_per_episode: 1024  
  use_physics_sim: True  # strictly speaking the original code had this at False
  gravity: [0, 0, -9.8]
  physics_steps_per_env_step: 1
  sim_step: 0.00416666666  
  stat_buffer_size: 25  
  normalize_observations: False
  normalize_rewards: False
  robots:
    - type: "KR16" 
      config:
        name: "kr16_1"
        base_position: [0, 0, 0]
        base_orientation: [0, 0, 0]
        resting_angles: [0, -135, 90, 0, 90, 0]
        control_mode: 0
        xyz_delta: 0.005
        rpy_delta: 0.005
      sensors:
        - type: "LidarSensorKR16"
          config:
            update_steps: 1
            add_to_observation_space: True
            add_to_logging: True
            indicator_buckets: 11
            ray_start: 0.01
            ray_end: 0.65
            ray_setup:
              ee_forward: [1, 1]
              ee_cone: [2, 5]
              ee_side_circle: [5, 5]
              ee_back_cone: [2, 5]
              upper_arm: [8, 2]
            indicator: True
            activated_links: [0, 1, 2, 3, 4]
      goal:
        type: "PositionCollision"
        config:
          add_to_logging: True
          continue_after_success: True
          reward_success: 10
          reward_collision: -5
          reward_distance_mult: -0.01
          dist_threshold_start: 0.2
          dist_threshold_end : 0.01
          dist_threshold_increment_start: 0.01
          dist_threshold_increment_end: 0.001
          dist_threshold_overwrite: "None"

  world:
    type: "KukaShelfExperiment"
    config:
      workspace_boundaries: [-3, 3, -3, 3, 0.0, 3]
      shelves_positions: 
        - [-0.725, -1.25, 0.51]
        - [-0.725, 1.75, 0.51]
      shelves_rotations: 
        - [90, 0, 0]
        - [90, 0, 0]  # rpy in degrees
      humans_positions: 
        - [5, 5, 5]  # just to spawn them far away
        - [5, 5, 5]
        - [5, 5, 5]
        - [5, 5, 5]
      humans_rotations: 
        - [0, 0, -90]
        - [0, 0, 90]
        - [0, 0, 90]
        - [0, 0, 90]
      humans_trajectories: 
        - [[-0.55, 0.85, 1.0], [0.55, 0.85, 1.0]]
        - [[-0.75, 0.85, 1.0], [0.75, 0.85, 1.0]]
        - [[0.55, -0.85, 1.0], [-0.55, -0.85, 1.0]]
        - [[0.75, -0.85, 1.0], [-0.75, -0.85, 1.0]]
      humans_shuffle: True  # False: spawns one human for each pair of position, rotation, trajectory, True: spawns one human with a random pair from all positions, rotations, trajectories
      target_pos_override: []
      target_rot_override: []
      start_override: []
      shelf_params:
        rows: 3
        cols: 4
        element_size: 0.35
        shelf_depth: 0.5
        wall_thickness: 0.01
      